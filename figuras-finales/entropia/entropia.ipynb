{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "from glob import glob\n",
    "import os\n",
    "import ordpy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prob_points(*args, facecolors=None, alpha=None, capsize=10, elinewidth=10, capthick=6, dot_size=400, yticks=None, ytickslabels=None, ymin=None, ymax=None, random_state=10, zero_line=False, edge_color=\"none\"):\n",
    "    np.random.seed(random_state)\n",
    "    SPREAD_LENGTH = 0.1\n",
    "    \n",
    "    x_list = np.arange(1.0, 1.0+0.5*len(args), 0.5)\n",
    "    y_list = list(map(lambda x: x.mean(), args))\n",
    "    error_list = list(map(lambda x: x.std()/np.sqrt(len(x)), args))\n",
    "    spread_list = x_list - SPREAD_LENGTH/2.0\n",
    "    \n",
    "    # create points for means and standard errors\n",
    "    fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "    ax.errorbar(x_list, y_list, error_list, ls=\"none\", capsize=capsize, elinewidth=elinewidth, capthick=capthick, ecolor=\"black\")\n",
    "    ax.scatter(x_list, y_list, s=dot_size, c=\"black\", zorder=10)\n",
    "    \n",
    "    if facecolors is None:\n",
    "        facecolors = np.repeat(\"#cccccc\", len(args))\n",
    "    if alpha is None:\n",
    "        alpha = np.repeat(0.5, len(args))\n",
    "\n",
    "    if type(facecolors) == str:\n",
    "        facecolors = np.repeat(facecolors, len(args))\n",
    "    if type(alpha) == float or type(alpha) == int:\n",
    "        alpha = np.repeat(alpha, len(args))\n",
    "    \n",
    "    if zero_line:\n",
    "        ax.plot([1.0-0.4, max(x_list)+0.4], [0, 0], c=\"#cccccc\", linestyle=\"dashed\", linewidth=elinewidth, zorder=0)\n",
    "\n",
    "    # draw each point\n",
    "    for i, arg in enumerate(args):\n",
    "        ax.scatter(\n",
    "            np.random.rand(len(arg))*SPREAD_LENGTH + spread_list[i], \n",
    "            arg, \n",
    "            c=facecolors[i], \n",
    "            edgecolors=edge_color, \n",
    "            s=dot_size, \n",
    "            alpha=alpha[i],\n",
    "            zorder=0\n",
    "        )\n",
    "\n",
    "\n",
    "    ax.set_xlim([1.0-0.4, max(x_list)+0.4])\n",
    "    ax.set_xticks(x_list, np.repeat(\"\", len(args)))\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "    plt.setp(ax.spines.values(), linewidth=8)\n",
    "    \n",
    "    if ymin and ymax:\n",
    "        ax.set_ylim([ymin, ymax])\n",
    "    \n",
    "    if yticks:\n",
    "        if ytickslabels:\n",
    "            ax.set_yticks(yticks, ytickslabels)\n",
    "        else:\n",
    "            ax.set_yticks(yticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_DIR = \"/home/usuario/disco1/proyectos/2023-resting-state-estados-fMRI_conn\"\n",
    "N_rois = 300\n",
    "subs = sorted(glob(f\"{MAIN_DIR}/results/func_networks/ROIs_300inVol_MNI/*\"))\n",
    "N_subs = len(subs)\n",
    "subs_controles = sorted(glob(f\"{MAIN_DIR}/results/func_networks/ROIs_300inVol_MNI_controles/*\"))\n",
    "N_subs_controles = len(subs_controles)\n",
    "\n",
    "#por red funcional o ROI\n",
    "network_affiliation = np.loadtxt(\"/home/usuario/disco1/proyectos/2023-resting-state-estados-fMRI_conn/scripts/func_networks/masks/ROIs_300inVol_MNI/ROIs_CommunityAffiliation.txt\")\n",
    "network_names = [\"DMN\", \"VIS\", \"FP\", \"Rew\", \"DA\", \"VA\", \"SN\", \"CO\", \"SMD\", \"SML\", \"AUD\", \"PM\", \"MTL\", \"un\"]\n",
    "network_list = np.unique(network_affiliation)\n",
    "network_list = network_list[:-1]\n",
    "\n",
    "he_matrix = np.zeros((N_subs, 4, N_rois)) #subs x conditions\n",
    "sc_matrix = np.zeros((N_subs, 4, N_rois)) #subs x conditions\n",
    "he_matrix_network = np.zeros((N_subs, 4, 13)) #subs x conditions\n",
    "sc_matrix_network = np.zeros((N_subs, 4, 13)) #subs x conditions\n",
    "he_matrix_controles = np.zeros((N_subs_controles, 4, N_rois)) #subs x conditions\n",
    "sc_matrix_controles = np.zeros((N_subs_controles, 4, N_rois)) #subs x conditions\n",
    "\n",
    "data_avp = np.zeros((N_subs, 4, N_rois, 150))\n",
    "data_data_controles = np.zeros((N_subs_controles, 4, N_rois, 150))\n",
    "for iSub, sub in enumerate(subs):\n",
    "    print(f\"{os.path.basename(sub)}\")\n",
    "    for iCond in [0,1,2,3]:\n",
    "        data = sio.loadmat(f\"{sub}/cond{iCond+1}/func_roi.mat\")[\"func_roi\"]\n",
    "        for iRoi in range(N_rois):\n",
    "            if network_affiliation[iRoi] == 18:\n",
    "                he_matrix[iSub, iCond, iRoi] = np.nan\n",
    "                sc_matrix[iSub, iCond, iRoi] = np.nan\n",
    "                continue\n",
    "                \n",
    "            he, sc = ordpy.complexity_entropy(data[iRoi,:], dx=3)\n",
    "            he_matrix[iSub, iCond, iRoi] = he\n",
    "            sc_matrix[iSub, iCond, iRoi] = sc\n",
    "            data_avp[iSub, iCond, iRoi, :] = data[iRoi,:]\n",
    "\n",
    "for iSub, sub in enumerate(subs_controles):\n",
    "    print(f\"{os.path.basename(sub)}\")\n",
    "    for iCond in [0,1,2,3]:\n",
    "        data_controles = sio.loadmat(f\"{sub}/cond{iCond+1}/func_roi.mat\")[\"func_roi\"]\n",
    "        for iRoi in range(N_rois):\n",
    "            # if network_affiliation[iRoi] == 18:\n",
    "            #     he_matrix_controles[iSub, iCond, iRoi] = np.nan\n",
    "            #     sc_matrix_controles[iSub, iCond, iRoi] = np.nan\n",
    "            #     continue\n",
    "                \n",
    "            he, sc = ordpy.complexity_entropy(data_controles[iRoi,:], dx=3)\n",
    "            he_matrix_controles[iSub, iCond, iRoi] = he\n",
    "            sc_matrix_controles[iSub, iCond, iRoi] = sc\n",
    "            data_data_controles[iSub, iCond, iRoi, :] = data_controles[iRoi,:]\n",
    "            \n",
    "for iSub, sub in enumerate(subs):\n",
    "    print(os.path.basename(sub))\n",
    "    for iCond in [0,1,2,3]:\n",
    "        data = sio.loadmat(f\"{sub}/cond{iCond+1}/func_roi.mat\")[\"func_roi\"]\n",
    "        for iNetwork, Network in enumerate(network_list):\n",
    "            serie = np.mean(data[network_affiliation == Network, :], axis=0)\n",
    "                \n",
    "            he, sc = ordpy.complexity_entropy(serie, dx=3)\n",
    "            he_matrix_network[iSub, iCond, iNetwork] = he\n",
    "            sc_matrix_network[iSub, iCond, iNetwork] = sc\n",
    "\n",
    "REMOVE_REPOSO = 7-1\n",
    "REMOVE_ALTERACION = 5-1\n",
    "he_matrix_controles[REMOVE_REPOSO, 0, :] = np.nan\n",
    "sc_matrix_controles[REMOVE_REPOSO, 0, :] = np.nan\n",
    "he_matrix_controles[REMOVE_ALTERACION, 2, :] = np.nan\n",
    "sc_matrix_controles[REMOVE_ALTERACION, 2, :] = np.nan\n",
    "\n",
    "data_data_controles[REMOVE_REPOSO, 0, :, :] = np.nan\n",
    "data_data_controles[REMOVE_REPOSO, 0, :, :] = np.nan\n",
    "data_data_controles[REMOVE_ALTERACION, 2, :, :] = np.nan\n",
    "data_data_controles[REMOVE_ALTERACION, 2, :, :] = np.nan\n",
    "\n",
    "he_matrix_controles = he_matrix_controles[:,:,0:288]\n",
    "sc_matrix_controles = sc_matrix_controles[:,:,0:288]\n",
    "he_matrix = he_matrix[:,:,0:288]\n",
    "sc_matrix = sc_matrix[:,:,0:288]\n",
    "\n",
    "data_data_controles = data_data_controles[:,:,0:288,:]\n",
    "data_avp = data_avp[:,:,0:288,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_complexity_stats(he_matrix_network, sc_matrix_network):\n",
    "    \n",
    "    df_data = {\"session\": [], \"cond\": [], \"network\": [], \"he\": [], \"sc\": [], \"roi\": []}\n",
    "    for iSub in range(20):\n",
    "        for iCond in range(4):\n",
    "            for iRoi in range(288):\n",
    "                df_data[\"session\"].append(iSub+1)\n",
    "                df_data[\"cond\"].append(iCond+1)\n",
    "                df_data[\"network\"].append(network_affiliation[iRoi+12])\n",
    "                df_data[\"roi\"].append(iRoi)\n",
    "                df_data[\"he\"].append(he_matrix[iSub, iCond, iRoi+12]) #las primeras 12 son unc.\n",
    "                df_data[\"sc\"].append(sc_matrix[iSub, iCond, iRoi+12])\n",
    "\n",
    "    df = pd.DataFrame(df_data)\n",
    "    df['cond'] = df['cond'].astype('category')\n",
    "    df['network'] = df['network'].astype('category')\n",
    "    df['roi'] = df['roi'].astype('category')\n",
    "    df['session'] = df['session'].astype('category')\n",
    "\n",
    "    md = smf.mixedlm(\"he ~ network + cond - 1\", df, groups=df[\"session\"])\n",
    "    mdf = md.fit()\n",
    "    mdf.summary()\n",
    "\n",
    "    all_data = pd.DataFrame({\"pvalues\": mdf.pvalues[:-1], \"tvalues\": mdf.tvalues[:-1]})\n",
    "    significant_data = all_data[all_data[\"pvalues\"] < 0.05]\n",
    "\n",
    "    return all_data, significant_data\n",
    "\n",
    "all_data_sc, significant_data_sc = calc_complexity_stats(he_matrix_network, sc_matrix_network)\n",
    "all_data_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, pcorregido = fdrcorrection(all_data_sc[\"pvalues\"][-3:].values, alpha=0.05, method=\"indep\", is_sorted=False)\n",
    "h, pcorregido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_entropy_complexity(condicion: str) -> (float, float):\n",
    "    condiciones = {\"trans\": 0, \"alter\": 1, \"recup\": 2}\n",
    "    index = condiciones[condicion]\n",
    "\n",
    "    he_per_subject = np.nanmean(he_matrix, axis=2)\n",
    "    sc_per_subject = np.nanmean(sc_matrix, axis=2)\n",
    "    he_controles_per_subject = np.nanmean(he_matrix_controles, axis=2)\n",
    "    sc_controles_per_subject = np.nanmean(sc_matrix_controles, axis=2)\n",
    "\n",
    "    he_diff = np.zeros((20, 3))\n",
    "    sc_diff = np.zeros((20, 3))\n",
    "    he_controles_diff = np.zeros((10,3))\n",
    "    sc_controles_diff = np.zeros((10,3))\n",
    "    he_diff[:,0] = he_per_subject[:,1] - he_per_subject[:,0]\n",
    "    he_diff[:,1] = he_per_subject[:,2] - he_per_subject[:,0]\n",
    "    he_diff[:,2] = he_per_subject[:,3] - he_per_subject[:,0]\n",
    "    sc_diff[:,0] = sc_per_subject[:,1] - sc_per_subject[:,0]\n",
    "    sc_diff[:,1] = sc_per_subject[:,2] - sc_per_subject[:,0]\n",
    "    sc_diff[:,2] = sc_per_subject[:,3] - sc_per_subject[:,0]\n",
    "    he_controles_diff[:,0] = he_controles_per_subject[:,1] - he_controles_per_subject[:,0]\n",
    "    he_controles_diff[:,1] = he_controles_per_subject[:,2] - he_controles_per_subject[:,0]\n",
    "    he_controles_diff[:,2] = he_controles_per_subject[:,3] - he_controles_per_subject[:,0]\n",
    "    sc_controles_diff[:,0] = sc_controles_per_subject[:,1] - sc_controles_per_subject[:,0]\n",
    "    sc_controles_diff[:,1] = sc_controles_per_subject[:,2] - sc_controles_per_subject[:,0]\n",
    "    sc_controles_diff[:,2] = sc_controles_per_subject[:,3] - sc_controles_per_subject[:,0]\n",
    "\n",
    "    N_perm = 50_000\n",
    "    d_list_he = np.zeros(N_perm)\n",
    "    d_list_sc = np.zeros(N_perm)\n",
    "    for perm in tqdm(range(N_perm)):\n",
    "        data_he = np.hstack((he_controles_diff[:,index], he_controles_diff[:,index], he_diff[:,index]))\n",
    "        data_sc = np.hstack((sc_controles_diff[:,index], sc_controles_diff[:,index], sc_diff[:,index]))\n",
    "        \n",
    "        np.random.shuffle(data_he)\n",
    "        np.random.shuffle(data_sc)\n",
    "\n",
    "        d_he = np.nanmean(data_he[0:20]) - np.nanmean(data_he[20:40])\n",
    "        d_sc = np.nanmean(data_sc[0:20]) - np.nanmean(data_sc[20:40])\n",
    "\n",
    "        d_list_he[perm] = d_he\n",
    "        d_list_sc[perm] = d_sc\n",
    "\n",
    "    x_he = np.nanmean(he_controles_diff[:,index]) - np.nanmean(he_diff[:,index])\n",
    "    x_sc = np.nanmean(sc_controles_diff[:,index]) - np.nanmean(sc_diff[:,index])\n",
    "    z_he = np.sign(x_he)\n",
    "    z_sc = np.sign(x_sc)\n",
    "\n",
    "    p_he = np.sum(d_list_he > np.abs(x_he))/len(d_list_he)\n",
    "    p_sc = np.sum(d_list_sc > np.abs(x_sc))/len(d_list_sc)\n",
    "    \n",
    "    return p_he, p_sc, d_list_he, d_list_sc, x_he, x_sc, z_he, z_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_he = [0, 0, 0]\n",
    "p_sc = [0, 0, 0]\n",
    "z_he = [0, 0, 0]\n",
    "z_sc = [0, 0, 0]\n",
    "p_he[0], p_sc[0], d_list_he_trans, d_list_sc_trans, x_he_trans, x_sc_trans, z_he[0], z_sc[0] = bootstrap_entropy_complexity(\"trans\")\n",
    "p_he[1], p_sc[1], d_list_he_alter, d_list_sc_alter, x_he_alter, x_sc_alter, z_he[1], z_sc[1]  = bootstrap_entropy_complexity(\"alter\")\n",
    "p_he[2], p_sc[2], d_list_he_recup, d_list_sc_recup, x_he_recup, x_sc_recup, z_he[2], z_sc[2] = bootstrap_entropy_complexity(\"recup\")\n",
    "\n",
    "df_graph = pd.DataFrame({\"condicion\": [\"trans\", \"alter\", \"recup\"], \"he\": p_he, \"z_he\": z_he, \"sc\": p_sc, \"z_sc\": z_sc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, pcorregido = fdrcorrection(df_graph[\"he\"].values, alpha=0.05, method=\"indep\", is_sorted=False)\n",
    "h, pcorregido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, pcorregido = fdrcorrection(df_graph[\"sc\"].values, alpha=0.05, method=\"indep\", is_sorted=False)\n",
    "h, pcorregido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_mean = np.mean(np.nanmean(he_matrix, axis=2), axis=0)\n",
    "he_stderr = np.std(np.nanmean(he_matrix, axis=2), axis=0)/np.sqrt(N_subs)\n",
    "he_per_subject = np.nanmean(he_matrix, axis=2)\n",
    "\n",
    "plot_prob_points(\n",
    "    he_per_subject[:,0], \n",
    "    he_per_subject[:,1], \n",
    "    he_per_subject[:,2], \n",
    "    he_per_subject[:,3], \n",
    "    facecolors=\"b\", \n",
    "    alpha=0.25,\n",
    "    capsize=5, \n",
    "    elinewidth=5, \n",
    "    capthick=5,\n",
    "    dot_size=500,\n",
    "    #zero_line=True,\n",
    "    #edge_color=\"black\",\n",
    "    #yticks=[-0.02, 0.000, 0.02, 0.04, 0.06, 0.08, 0.10],\n",
    "    #ytickslabels=[\"-0.02\", \"0.00\", \"0.02\", \"0.04\", \"0.06\", \"0.08\", \"0.10\"]\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/home/usuario/disco1/proyectos/2023-resting-state-estados-fMRI_conn/scripts/figuras-finales/entropia/figuras/he.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_mean = np.mean(np.nanmean(sc_matrix, axis=2), axis=0)\n",
    "sc_stderr = np.std(np.nanmean(sc_matrix, axis=2), axis=0)/np.sqrt(N_subs)\n",
    "sc_per_subject = np.nanmean(sc_matrix, axis=2)\n",
    "\n",
    "plot_prob_points(\n",
    "    sc_per_subject[:,0], \n",
    "    sc_per_subject[:,1], \n",
    "    sc_per_subject[:,2], \n",
    "    sc_per_subject[:,3], \n",
    "    facecolors=\"b\", \n",
    "    alpha=0.25,\n",
    "    capsize=5, \n",
    "    elinewidth=5, \n",
    "    capthick=5,\n",
    "    dot_size=500,\n",
    "    #zero_line=True,\n",
    "    #edge_color=\"black\",\n",
    "    #yticks=[-0.02, 0.000, 0.02, 0.04, 0.06, 0.08, 0.10],\n",
    "    #ytickslabels=[\"-0.02\", \"0.00\", \"0.02\", \"0.04\", \"0.06\", \"0.08\", \"0.10\"]\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/home/usuario/disco1/proyectos/2023-resting-state-estados-fMRI_conn/scripts/figuras-finales/entropia/figuras/sc.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_per_subject = np.nanmean(he_matrix_controles, axis=2)\n",
    "\n",
    "a = he_per_subject\n",
    "a\n",
    "\n",
    "plot_prob_points(\n",
    "    he_per_subject[[0,1,2,3,4,5,7,8,9],0], \n",
    "    he_per_subject[:,1], \n",
    "    he_per_subject[[0,1,2,3,5,7,8,9],2], \n",
    "    he_per_subject[:,3], \n",
    "    facecolors=\"b\", \n",
    "    alpha=0.25,\n",
    "    capsize=5, \n",
    "    elinewidth=5, \n",
    "    capthick=5,\n",
    "    dot_size=500,\n",
    "    #zero_line=True,\n",
    "    #edge_color=\"black\",\n",
    "    #yticks=[-0.02, 0.000, 0.02, 0.04, 0.06, 0.08, 0.10],\n",
    "    #ytickslabels=[\"-0.02\", \"0.00\", \"0.02\", \"0.04\", \"0.06\", \"0.08\", \"0.10\"]\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/home/usuario/disco1/proyectos/2023-resting-state-estados-fMRI_conn/scripts/figuras-finales/entropia/figuras/he_controles.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_mean = np.mean(np.nanmean(sc_matrix_controles, axis=2), axis=0)\n",
    "sc_stderr = np.std(np.nanmean(sc_matrix_controles, axis=2), axis=0)/np.sqrt(N_subs)\n",
    "sc_per_subject = np.nanmean(sc_matrix_controles, axis=2)\n",
    "\n",
    "plot_prob_points(\n",
    "    sc_per_subject[:,0], \n",
    "    sc_per_subject[:,1], \n",
    "    sc_per_subject[:,2], \n",
    "    sc_per_subject[:,3], \n",
    "    facecolors=\"b\", \n",
    "    alpha=0.25,\n",
    "    capsize=5, \n",
    "    elinewidth=5, \n",
    "    capthick=5,\n",
    "    dot_size=500,\n",
    "    #zero_line=True,\n",
    "    #edge_color=\"black\",\n",
    "    #yticks=[-0.02, 0.000, 0.02, 0.04, 0.06, 0.08, 0.10],\n",
    "    #ytickslabels=[\"-0.02\", \"0.00\", \"0.02\", \"0.04\", \"0.06\", \"0.08\", \"0.10\"]\n",
    ")\n",
    "\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"/home/usuario/disco1/proyectos/2023-resting-state-estados-fMRI_conn/scripts/figuras-finales/entropia/figuras/sc_controles.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_per_subject = np.nanmean(he_matrix_controles, axis=2)\n",
    "\n",
    "plt.bar([1,2,3,4], np.nanmean(he_per_subject, axis=0))\n",
    "plt.ylim([0.79, 0.81])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_per_subject = np.nanmean(he_matrix, axis=2)\n",
    "\n",
    "plt.bar([1,2,3,4], np.nanmean(he_per_subject, axis=0))\n",
    "plt.ylim([0.89, 0.91])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
